<!DOCTYPE html>

<html lang="en">
  <head>
    <meta charset="utf-8" />
    <meta name="viewport" content="width=device-width, initial-scale=1.0" />
    <meta
      name="generator"
      content="Docutils 0.18.1: http://docutils.sourceforge.net/"
    />

    <title>Machine Learning Model &#8212; Mortality Prediction</title>

    <script data-cfasync="false">
      document.documentElement.dataset.mode =
        localStorage.getItem('mode') || '';
      document.documentElement.dataset.theme =
        localStorage.getItem('theme') || 'light';
    </script>

    <!-- Loaded before other Sphinx assets -->
    <link
      href="_static/styles/theme.css?digest=e353d410970836974a52"
      rel="stylesheet"
    />
    <link
      href="_static/styles/bootstrap.css?digest=e353d410970836974a52"
      rel="stylesheet"
    />
    <link
      href="_static/styles/pydata-sphinx-theme.css?digest=e353d410970836974a52"
      rel="stylesheet"
    />

    <link
      href="_static/vendor/fontawesome/6.1.2/css/all.min.css?digest=e353d410970836974a52"
      rel="stylesheet"
    />
    <link
      rel="preload"
      as="font"
      type="font/woff2"
      crossorigin
      href="_static/vendor/fontawesome/6.1.2/webfonts/fa-solid-900.woff2"
    />
    <link
      rel="preload"
      as="font"
      type="font/woff2"
      crossorigin
      href="_static/vendor/fontawesome/6.1.2/webfonts/fa-brands-400.woff2"
    />
    <link
      rel="preload"
      as="font"
      type="font/woff2"
      crossorigin
      href="_static/vendor/fontawesome/6.1.2/webfonts/fa-regular-400.woff2"
    />

    <link rel="stylesheet" type="text/css" href="_static/pygments.css" />
    <link
      rel="stylesheet"
      href="_static/styles/sphinx-book-theme.css?digest=14f4ca6b54d191a8c7657f6c759bf11a5fb86285"
      type="text/css"
    />
    <link rel="stylesheet" type="text/css" href="_static/togglebutton.css" />
    <link rel="stylesheet" type="text/css" href="_static/copybutton.css" />
    <link
      rel="stylesheet"
      type="text/css"
      href="_static/mystnb.4510f1fc1dee50b3e5859aac5469c37c29e427902b24a333a5f9fcb2f0b3ac41.css"
    />
    <link rel="stylesheet" type="text/css" href="_static/sphinx-thebe.css" />
    <link
      rel="stylesheet"
      type="text/css"
      href="_static/design-style.4045f2051d55cab465a707391d5b2007.min.css"
    />

    <!-- Pre-loaded scripts that we'll load fully later -->
    <link
      rel="preload"
      as="script"
      href="_static/scripts/bootstrap.js?digest=e353d410970836974a52"
    />
    <link
      rel="preload"
      as="script"
      href="_static/scripts/pydata-sphinx-theme.js?digest=e353d410970836974a52"
    />

    <script
      data-url_root="./"
      id="documentation_options"
      src="_static/documentation_options.js"
    ></script>
    <script src="_static/jquery.js"></script>
    <script src="_static/underscore.js"></script>
    <script src="_static/_sphinx_javascript_frameworks_compat.js"></script>
    <script src="_static/doctools.js"></script>
    <script src="_static/clipboard.min.js"></script>
    <script src="_static/copybutton.js"></script>
    <script src="_static/scripts/sphinx-book-theme.js?digest=5a5c038af52cf7bc1a1ec88eea08e6366ee68824"></script>
    <script>
      let toggleHintShow = 'Click to show';
    </script>
    <script>
      let toggleHintHide = 'Click to hide';
    </script>
    <script>
      let toggleOpenOnPrint = 'true';
    </script>
    <script src="_static/togglebutton.js"></script>
    <script>
      var togglebuttonSelector = '.toggle, .admonition.dropdown';
    </script>
    <script src="_static/design-tabs.js"></script>
    <script>
      const THEBE_JS_URL = 'https://unpkg.com/thebe@0.8.2/lib/index.js';
      const thebe_selector = '.thebe,.cell';
      const thebe_selector_input = 'pre';
      const thebe_selector_output = '.output, .cell_output';
    </script>
    <script async="async" src="_static/sphinx-thebe.js"></script>
    <script>
      window.MathJax = {
        options: {
          processHtmlClass: 'tex2jax_process|mathjax_process|math|output_area',
        },
      };
    </script>
    <script
      defer="defer"
      src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js"
    ></script>
    <script>
      DOCUMENTATION_OPTIONS.pagename = 'machine-learning';
    </script>
    <link rel="shortcut icon" href="_static/favicon.png" />
    <link rel="index" title="Index" href="genindex.html" />
    <link rel="search" title="Search" href="search.html" />
    <link
      rel="prev"
      title="Visualizing Relations Between Features"
      href="relations-visualization.html"
    />
    <meta name="viewport" content="width=device-width, initial-scale=1" />
    <meta name="docsearch:language" content="en" />
  </head>

  <body
    data-bs-spy="scroll"
    data-bs-target=".bd-toc-nav"
    data-offset="180"
    data-bs-root-margin="0px 0px -60%"
    data-default-mode=""
  >
    <a class="skip-link" href="#main-content">Skip to main content</a>

    <input
      type="checkbox"
      class="sidebar-toggle"
      name="__primary"
      id="__primary"
    />
    <label class="overlay overlay-primary" for="__primary"></label>

    <input
      type="checkbox"
      class="sidebar-toggle"
      name="__secondary"
      id="__secondary"
    />
    <label class="overlay overlay-secondary" for="__secondary"></label>

    <div class="search-button__wrapper">
      <div class="search-button__overlay"></div>
      <div class="search-button__search-container">
        <form
          class="bd-search d-flex align-items-center"
          action="search.html"
          method="get"
        >
          <i class="fa-solid fa-magnifying-glass"></i>
          <input
            type="search"
            class="form-control"
            name="q"
            id="search-input"
            placeholder="Search this book..."
            aria-label="Search this book..."
            autocomplete="off"
            autocorrect="off"
            autocapitalize="off"
            spellcheck="false"
          />
          <span class="search-button__kbd-shortcut"
            ><kbd class="kbd-shortcut__modifier">Ctrl</kbd>+<kbd>K</kbd></span
          >
        </form>
      </div>
    </div>

    <nav class="bd-header navbar navbar-expand-lg bd-navbar"></nav>

    <div class="bd-container">
      <div class="bd-container__inner bd-page-width">
        <div class="bd-sidebar-primary bd-sidebar">
          <div class="sidebar-header-items sidebar-primary__section"></div>

          <div class="sidebar-primary-items__start sidebar-primary__section">
            <div class="sidebar-primary-item">
              <a class="navbar-brand logo" href="intro.html">
                <img
                  src="_static/logo.png"
                  class="logo__image only-light"
                  alt="Logo image"
                />
                <script>
                  document.write(
                    `<img src="_static/logo.png" class="logo__image only-dark" alt="Logo image"/>`
                  );
                </script>
              </a>
            </div>
            <div class="sidebar-primary-item">
              <nav class="bd-links" id="bd-docs-nav" aria-label="Main">
                <div class="bd-toc-item navbar-nav active">
                  <ul class="nav bd-sidenav bd-sidenav__home-link">
                    <li class="toctree-l1">
                      <a class="reference internal" href="intro.html">
                        Introduction
                      </a>
                    </li>
                  </ul>
                  <ul class="current nav bd-sidenav">
                    <li class="toctree-l1">
                      <a class="reference internal" href="data-description.html"
                        >Data Description</a
                      >
                    </li>
                    <li class="toctree-l1">
                      <a
                        class="reference internal"
                        href="data-preparation-eda.html"
                        >Data Preparation and EDA</a
                      >
                    </li>
                    <li class="toctree-l1">
                      <a
                        class="reference internal"
                        href="dealing-with-outliers.html"
                        >Dealing with Outliers</a
                      >
                    </li>
                    <li class="toctree-l1">
                      <a
                        class="reference internal"
                        href="features-transformations.html"
                        >Features Transformations</a
                      >
                    </li>
                    <li class="toctree-l1">
                      <a
                        class="reference internal"
                        href="categorical-visualization.html"
                        >Visualizing Categorical Data</a
                      >
                    </li>
                    <li class="toctree-l1">
                      <a
                        class="reference internal"
                        href="measures-central-tendency-dispersion.html"
                        >Calculating the Measures Of Central Tendancy and
                        Dispersion</a
                      >
                    </li>
                    <li class="toctree-l1">
                      <a
                        class="reference internal"
                        href="features-standardization.html"
                        >Features Standardization</a
                      >
                    </li>
                    <li class="toctree-l1">
                      <a class="reference internal" href="data-splitting.html"
                        >Splitting Data</a
                      >
                    </li>
                    <li class="toctree-l1">
                      <a
                        class="reference internal"
                        href="conditional-distributions.html"
                        >Plotting Conditional Distributions</a
                      >
                    </li>
                    <li class="toctree-l1">
                      <a
                        class="reference internal"
                        href="normal-distribution-testing.html"
                        >Normal Distribution Statistically Testing</a
                      >
                    </li>
                    <li class="toctree-l1">
                      <a
                        class="reference internal"
                        href="relations-visualization.html"
                        >Visualizing Relations Between Features</a
                      >
                    </li>
                    <li class="toctree-l1 current active">
                      <a class="current reference internal" href="#"
                        >Machine Learning Model</a
                      >
                    </li>
                  </ul>
                </div>
              </nav>
            </div>
          </div>

          <div
            class="sidebar-primary-items__end sidebar-primary__section"
          ></div>

          <div id="rtd-footer-container"></div>
        </div>

        <main id="main-content" class="bd-main">
          <div class="sbt-scroll-pixel-helper"></div>

          <div class="bd-content">
            <div class="bd-article-container">
              <div class="bd-header-article">
                <div class="header-article-items header-article__inner">
                  <div class="header-article-items__start">
                    <div class="header-article-item">
                      <label
                        class="sidebar-toggle primary-toggle btn btn-sm"
                        for="__primary"
                        title="Toggle primary sidebar"
                        data-bs-placement="bottom"
                        data-bs-toggle="tooltip"
                      >
                        <span class="fa-solid fa-bars"></span>
                      </label>
                    </div>
                  </div>

                  <div class="header-article-items__end">
                    <div class="header-article-item">
                      <div class="article-header-buttons">
                        <a
                          href="https://github.com/Bodykudo/Mortality-Prediction-Model"
                          target="_blank"
                          class="btn btn-sm btn-source-repository-button"
                          title="Source repository"
                          data-bs-placement="bottom"
                          data-bs-toggle="tooltip"
                        >
                          <span class="btn__icon-container">
                            <i class="fab fa-github"></i>
                          </span>
                        </a>

                        <div class="dropdown dropdown-download-buttons">
                          <button
                            class="btn dropdown-toggle"
                            type="button"
                            data-bs-toggle="dropdown"
                            aria-expanded="false"
                            aria-label="Download this page"
                          >
                            <i class="fas fa-download"></i>
                          </button>
                          <ul class="dropdown-menu">
                            <li>
                              <a
                                href="_sources/machine-learning.ipynb"
                                target="_blank"
                                class="btn btn-sm btn-download-source-button dropdown-item"
                                title="Download source file"
                                data-bs-placement="left"
                                data-bs-toggle="tooltip"
                              >
                                <span class="btn__icon-container">
                                  <i class="fas fa-file"></i>
                                </span>
                                <span class="btn__text-container">.ipynb</span>
                              </a>
                            </li>

                            <li>
                              <button
                                onclick="window.print()"
                                class="btn btn-sm btn-download-pdf-button dropdown-item"
                                title="Print to PDF"
                                data-bs-placement="left"
                                data-bs-toggle="tooltip"
                              >
                                <span class="btn__icon-container">
                                  <i class="fas fa-file-pdf"></i>
                                </span>
                                <span class="btn__text-container">.pdf</span>
                              </button>
                            </li>
                          </ul>
                        </div>

                        <button
                          onclick="toggleFullScreen()"
                          class="btn btn-sm btn-fullscreen-button"
                          title="Fullscreen mode"
                          data-bs-placement="bottom"
                          data-bs-toggle="tooltip"
                        >
                          <span class="btn__icon-container">
                            <i class="fas fa-expand"></i>
                          </span>
                        </button>

                        <script>
                          document.write(`
  <button class="theme-switch-button btn btn-sm btn-outline-primary navbar-btn rounded-circle" title="light/dark" aria-label="light/dark" data-bs-placement="bottom" data-bs-toggle="tooltip">
    <span class="theme-switch" data-mode="light"><i class="fa-solid fa-sun"></i></span>
    <span class="theme-switch" data-mode="dark"><i class="fa-solid fa-moon"></i></span>
    <span class="theme-switch" data-mode="auto"><i class="fa-solid fa-circle-half-stroke"></i></span>
  </button>
`);
                        </script>

                        <script>
                          document.write(`
  <button class="btn btn-sm navbar-btn search-button search-button__button" title="Search" aria-label="Search" data-bs-placement="bottom" data-bs-toggle="tooltip">
    <i class="fa-solid fa-magnifying-glass"></i>
  </button>
`);
                        </script>
                        <label
                          class="sidebar-toggle secondary-toggle btn btn-sm"
                          for="__secondary"
                          title="Toggle secondary sidebar"
                          data-bs-placement="bottom"
                          data-bs-toggle="tooltip"
                        >
                          <span class="fa-solid fa-list"></span>
                        </label>
                      </div>
                    </div>
                  </div>
                </div>
              </div>

              <div id="jb-print-docs-body" class="onlyprint">
                <h1>Machine Learning Model</h1>
                <!-- Table of contents -->
                <div id="print-main-content">
                  <div id="jb-print-toc">
                    <div>
                      <h2>Contents</h2>
                    </div>
                    <nav aria-label="Page">
                      <ul class="visible nav section-nav flex-column">
                        <li class="toc-h2 nav-item toc-entry">
                          <a
                            class="reference internal nav-link"
                            href="#naive-bayes-classifier"
                            >Naive Bayes Classifier</a
                          >
                          <ul class="nav section-nav flex-column">
                            <li class="toc-h3 nav-item toc-entry">
                              <a
                                class="reference internal nav-link"
                                href="#naive-bayes-classifier-from-scratch"
                                >Naive Bayes Classifier from Scratch</a
                              >
                            </li>
                            <li class="toc-h3 nav-item toc-entry">
                              <a
                                class="reference internal nav-link"
                                href="#built-in-naive-bayes-classifier"
                                >Built-in Naive Bayes Classifier</a
                              >
                            </li>
                          </ul>
                        </li>
                        <li class="toc-h2 nav-item toc-entry">
                          <a
                            class="reference internal nav-link"
                            href="#adaboost-classifier"
                            >Adaboost Classifier</a
                          >
                        </li>
                        <li class="toc-h2 nav-item toc-entry">
                          <a
                            class="reference internal nav-link"
                            href="#random-forest-classifier-model"
                            >Random Forest Classifier Model</a
                          >
                          <ul class="nav section-nav flex-column">
                            <li class="toc-h3 nav-item toc-entry">
                              <a
                                class="reference internal nav-link"
                                href="#rf-classifier"
                                >RF Classifier</a
                              >
                            </li>
                            <li class="toc-h3 nav-item toc-entry">
                              <a
                                class="reference internal nav-link"
                                href="#features-impact-on-rf-model-s-prediction"
                                >Features Impact on RF Model’s Prediction</a
                              >
                            </li>
                            <li class="toc-h3 nav-item toc-entry">
                              <a
                                class="reference internal nav-link"
                                href="#visualizing-the-tree-ensembles"
                                >Visualizing the Tree Ensembles</a
                              >
                            </li>
                          </ul>
                        </li>
                        <li class="toc-h2 nav-item toc-entry">
                          <a
                            class="reference internal nav-link"
                            href="#using-an-ensemble-of-models-for-better-performance"
                            >Using an Ensemble of Models for Better
                            Performance</a
                          >
                        </li>
                      </ul>
                    </nav>
                  </div>
                </div>
              </div>

              <div id="searchbox"></div>
              <article class="bd-article" role="main">
                <section
                  class="tex2jax_ignore mathjax_ignore"
                  id="machine-learning-model"
                >
                  <h1>
                    Machine Learning Model<a
                      class="headerlink"
                      href="#machine-learning-model"
                      title="Permalink to this heading"
                      >#</a
                    >
                  </h1>
                  <div class="cell docutils container">
                    <div class="cell_input docutils container">
                      <div class="highlight-ipython3 notranslate">
                        <div class="highlight">
                          <pre><span></span><span class="c1"># Importing packages we will be using</span>
<span class="kn">import</span> <span class="nn">numpy</span> <span class="k">as</span> <span class="nn">np</span>
<span class="kn">import</span> <span class="nn">matplotlib.pyplot</span> <span class="k">as</span> <span class="nn">plt</span>
<span class="kn">from</span> <span class="nn">sklearn.naive_bayes</span> <span class="kn">import</span> <span class="n">GaussianNB</span>
<span class="kn">from</span> <span class="nn">sklearn.metrics</span> <span class="kn">import</span> <span class="n">roc_auc_score</span><span class="p">,</span> <span class="n">confusion_matrix</span><span class="p">,</span> <span class="n">ConfusionMatrixDisplay</span><span class="p">,</span> <span class="n">RocCurveDisplay</span><span class="p">,</span> <span class="n">accuracy_score</span><span class="p">,</span> <span class="n">roc_curve</span>
<span class="kn">from</span> <span class="nn">sklearn.ensemble</span> <span class="kn">import</span> <span class="n">AdaBoostClassifier</span><span class="p">,</span> <span class="n">RandomForestClassifier</span><span class="p">,</span> <span class="n">VotingClassifier</span><span class="p">,</span> <span class="n">RandomForestClassifier</span>
<span class="kn">from</span> <span class="nn">sklearn.model_selection</span> <span class="kn">import</span> <span class="n">RandomizedSearchCV</span>
<span class="kn">from</span> <span class="nn">sklearn.tree</span> <span class="kn">import</span> <span class="n">plot_tree</span>
<span class="kn">from</span> <span class="nn">sklearn.neural_network</span> <span class="kn">import</span> <span class="n">MLPClassifier</span>
<span class="kn">from</span> <span class="nn">sklearn.linear_model</span> <span class="kn">import</span> <span class="n">LogisticRegression</span>
<span class="kn">from</span> <span class="nn">sklearn.svm</span> <span class="kn">import</span> <span class="n">SVC</span>
<span class="kn">from</span> <span class="nn">sklearn.preprocessing</span> <span class="kn">import</span> <span class="n">StandardScaler</span>
<span class="kn">import</span> <span class="nn">shap</span>
<span class="kn">import</span> <span class="nn">mpld3</span>

<span class="o">%</span><span class="k">store</span> -r X_train X_test y_train y_test df
</pre>
                        </div>
                      </div>
                    </div>
                  </div>
                  <section id="naive-bayes-classifier">
                    <h2>
                      Naive Bayes Classifier<a
                        class="headerlink"
                        href="#naive-bayes-classifier"
                        title="Permalink to this heading"
                        >#</a
                      >
                    </h2>
                    <p>
                      <strong>The Naive Bayes classifier</strong> is a simple
                      yet effective probabilistic machine learning algorithm
                      used for classification tasks. It is based on Bayes’
                      theorem and makes the assumption of feature independence,
                      which is where the “naive” in its name comes from. The
                      Naive Bayes classifier is built on
                      <strong>Bayes Theorem</strong>:
                      <span class="math notranslate nohighlight"
                        >\(P(y|x) = \frac{P(x|y)P(y)}{P(x)}\)</span
                      >, Where:
                    </p>
                    <div class="math notranslate nohighlight">
                      \[ P(y|x) = \frac{P(x|y)P(y)}{P(x)} \]
                    </div>
                    <ul class="simple">
                      <li>
                        <p>
                          <span class="math notranslate nohighlight"
                            >\(P(x)\)</span
                          >: Prior probability of event
                          <span class="math notranslate nohighlight"
                            >\(x\)</span
                          >
                        </p>
                      </li>
                      <li>
                        <p>
                          <span class="math notranslate nohighlight"
                            >\(P(y)\)</span
                          >: Prior probability of event
                          <span class="math notranslate nohighlight"
                            >\(y\)</span
                          >
                        </p>
                      </li>
                      <li>
                        <p>
                          <span class="math notranslate nohighlight"
                            >\(P(x|y)\)</span
                          >: Probability of event
                          <span class="math notranslate nohighlight"
                            >\(x\)</span
                          >
                          given event
                          <span class="math notranslate nohighlight"
                            >\(y\)</span
                          >
                        </p>
                      </li>
                      <li>
                        <p>
                          <span class="math notranslate nohighlight"
                            >\(P(y|x)\)</span
                          >: Probability of event
                          <span class="math notranslate nohighlight"
                            >\(y\)</span
                          >
                          given event
                          <span class="math notranslate nohighlight"
                            >\(x\)</span
                          >
                        </p>
                      </li>
                    </ul>
                    <p>
                      Now, let’s assume that features are mutually independent
                      (Naive assumption), in our case we get the following
                      equation:
                      <span class="math notranslate nohighlight"
                        >\(P(y|\mathbf{X}) = \frac{\prod_{i=1}^{n}
                        P(x_i|y)P(y)}{P(\mathbf{X})}\)</span
                      >, where:
                    </p>
                    <ul class="simple">
                      <li>
                        <p>
                          <span class="math notranslate nohighlight">\(X\)</span
                          >: vector of features
                          <span class="math notranslate nohighlight"
                            >\((x_1, x_2, ..., x_n)\)</span
                          >
                        </p>
                      </li>
                      <li>
                        <p>
                          <span class="math notranslate nohighlight"
                            >\(x_i\)</span
                          >: Individual feature
                        </p>
                      </li>
                      <li>
                        <p>
                          <span class="math notranslate nohighlight">\(n\)</span
                          >: Number of features
                        </p>
                      </li>
                      <li>
                        <p>
                          <span class="math notranslate nohighlight">\(y\)</span
                          >: Event that the person would live in the next 10
                          years
                        </p>
                      </li>
                      <li>
                        <p>
                          <span class="math notranslate nohighlight"
                            >\(P(X)\)</span
                          >: Prior probability of features
                          <span class="math notranslate nohighlight"
                            >\(X\)</span
                          >
                        </p>
                      </li>
                      <li>
                        <p>
                          <span class="math notranslate nohighlight"
                            >\(P(y)\)</span
                          >: Prior probability of event
                          <span class="math notranslate nohighlight"
                            >\(y\)</span
                          >
                        </p>
                      </li>
                      <li>
                        <p>
                          <span class="math notranslate nohighlight"
                            >\(P(X|y)\)</span
                          >: Probability of features
                          <span class="math notranslate nohighlight"
                            >\(X\)</span
                          >
                          given event
                          <span class="math notranslate nohighlight"
                            >\(y\)</span
                          >
                          (LikeHood)
                        </p>
                      </li>
                      <li>
                        <p>
                          <span class="math notranslate nohighlight"
                            >\(P(y|X)\)</span
                          >: Probability of event
                          <span class="math notranslate nohighlight"
                            >\(y\)</span
                          >
                          given features
                          <span class="math notranslate nohighlight"
                            >\(X\)</span
                          >
                          (Posterior)
                        </p>
                      </li>
                    </ul>
                    <p>
                      Then to select class with highest posterior probability:
                      <span class="math notranslate nohighlight"
                        >\(y = \arg\max_y P(y|\mathbf{X}) = \arg\max_y
                        \frac{\prod_{i=1}^{n}
                        P(x_i|y)P(y)}{P(\mathbf{X})}\)</span
                      >
                    </p>
                    <p>
                      Since
                      <span class="math notranslate nohighlight"
                        >\({P(X)}\)</span
                      >
                      does not depend on our posterior probability at all we can
                      neglect it.<br />
                      <span class="math notranslate nohighlight"
                        >\(\arg\max_y P(y|\mathbf{X}) = \arg\max_y \left(
                        \prod_{i=1}^{n} P(x_i|y)P(y) \right)\)</span
                      >
                    </p>
                    <p>
                      Since the probabilities calculated by the Naive Bayes
                      classifier are typically between
                      <span class="math notranslate nohighlight">\(0\)</span>
                      and
                      <span class="math notranslate nohighlight">\(1\)</span>,
                      multiplying them together can result in very small
                      numbers. To overcome this issue, a common practice is to
                      apply the logarithm function to transform the
                      multiplication into addition. By taking the logarithm of
                      the probabilities, we can convert the product operation to
                      a summation, which helps avoid numerical underflow. This
                      approach allows for more stable computations and
                      facilitates easier manipulation of probabilities, the
                      formula of this method is given as:<br />
                      <span class="math notranslate nohighlight"
                        >\(y = \arg\max_y \left( \sum_{i=1}^{n} \log(P(x_i|y))
                        \right) + \log(P(y))\)</span
                      >
                    </p>
                    <p>Finally, We need to calculate the following:</p>
                    <ul class="simple">
                      <li>
                        <p>
                          <span class="math notranslate nohighlight"
                            >\(P(y)\)</span
                          >: Prior probability
                          <span class="math notranslate nohighlight"
                            >\(\rightarrow\)</span
                          >
                          Frequency of each class
                        </p>
                      </li>
                      <li>
                        <p>
                          <span class="math notranslate nohighlight"
                            >\(P(x_i|y)\)</span
                          >: Class conditional probability
                          <span class="math notranslate nohighlight"
                            >\(\rightarrow\)</span
                          >
                          Model with Gaussian
                        </p>
                      </li>
                    </ul>
                    <p>
                      We will calculate them using the following formula:
                      <span class="math notranslate nohighlight"
                        >\(P(x_{i}\mid y) = \frac{1}{\sqrt{2\pi \sigma_y^{2}}}
                        \exp \left(-\frac{(x_{i} -\mu_{y})^2}{2\sigma_y^{2}}
                        \right)\)</span
                      >
                    </p>
                    <section id="naive-bayes-classifier-from-scratch">
                      <h3>
                        Naive Bayes Classifier from Scratch<a
                          class="headerlink"
                          href="#naive-bayes-classifier-from-scratch"
                          title="Permalink to this heading"
                          >#</a
                        >
                      </h3>
                      <div class="cell docutils container">
                        <div class="cell_input docutils container">
                          <div class="highlight-ipython3 notranslate">
                            <div class="highlight">
                              <pre><span></span><span class="c1"># First, let&#39;s create our Naive Bayes Classifier from scratch</span>
<span class="k">class</span> <span class="nc">NaiveBayes</span><span class="p">:</span>
    <span class="k">def</span> <span class="nf">fit</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">X</span><span class="p">,</span> <span class="n">y</span><span class="p">):</span>
        <span class="n">n_samples</span><span class="p">,</span> <span class="n">n_features</span> <span class="o">=</span> <span class="n">X</span><span class="o">.</span><span class="n">shape</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">_classes</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">unique</span><span class="p">(</span><span class="n">y</span><span class="p">)</span>  <span class="c1"># 0 or 1</span>
        <span class="n">n_classes</span> <span class="o">=</span> <span class="nb">len</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">_classes</span><span class="p">)</span>

        <span class="bp">self</span><span class="o">.</span><span class="n">_mean</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">zeros</span><span class="p">((</span><span class="n">n_classes</span><span class="p">,</span> <span class="n">n_features</span><span class="p">),</span> <span class="n">dtype</span><span class="o">=</span><span class="n">np</span><span class="o">.</span><span class="n">float64</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">_var</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">zeros</span><span class="p">((</span><span class="n">n_classes</span><span class="p">,</span> <span class="n">n_features</span><span class="p">),</span> <span class="n">dtype</span><span class="o">=</span><span class="n">np</span><span class="o">.</span><span class="n">float64</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">_priors</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">zeros</span><span class="p">(</span><span class="n">n_classes</span><span class="p">,</span> <span class="n">dtype</span><span class="o">=</span><span class="n">np</span><span class="o">.</span><span class="n">float64</span><span class="p">)</span>
        <span class="k">for</span> <span class="n">i</span><span class="p">,</span> <span class="n">c</span> <span class="ow">in</span> <span class="nb">enumerate</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">_classes</span><span class="p">):</span>
            <span class="n">X_c</span> <span class="o">=</span> <span class="n">X</span><span class="p">[</span><span class="n">y</span> <span class="o">==</span> <span class="n">c</span><span class="p">]</span>
            <span class="c1"># Mean of each feature in each class</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">_mean</span><span class="p">[</span><span class="n">i</span><span class="p">,</span> <span class="p">:]</span> <span class="o">=</span> <span class="n">X_c</span><span class="o">.</span><span class="n">mean</span><span class="p">(</span><span class="n">axis</span><span class="o">=</span><span class="mi">0</span><span class="p">)</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">_var</span><span class="p">[</span><span class="n">i</span><span class="p">,</span> <span class="p">:]</span> <span class="o">=</span> <span class="n">X_c</span><span class="o">.</span><span class="n">var</span><span class="p">(</span><span class="n">axis</span><span class="o">=</span><span class="mi">0</span><span class="p">)</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">_priors</span><span class="p">[</span><span class="n">i</span><span class="p">]</span> <span class="o">=</span> <span class="n">X_c</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span> <span class="o">/</span> \
                <span class="nb">float</span><span class="p">(</span><span class="n">n_samples</span><span class="p">)</span>  <span class="c1"># Probability of each class</span>

    <span class="k">def</span> <span class="nf">predict</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">X</span><span class="p">):</span>
        <span class="n">Z</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">(</span><span class="n">X</span><span class="p">)</span>
        <span class="n">y_pred</span> <span class="o">=</span> <span class="p">[</span><span class="bp">self</span><span class="o">.</span><span class="n">_predict</span><span class="p">(</span><span class="n">x</span><span class="p">)</span> <span class="k">for</span> <span class="n">x</span> <span class="ow">in</span> <span class="n">Z</span><span class="p">]</span>
        <span class="k">return</span> <span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">(</span><span class="n">y_pred</span><span class="p">)</span>

    <span class="k">def</span> <span class="nf">_predict</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">x</span><span class="p">):</span>
        <span class="n">posteriors</span> <span class="o">=</span> <span class="p">[]</span>
        <span class="k">for</span> <span class="n">i</span><span class="p">,</span> <span class="n">c</span> <span class="ow">in</span> <span class="nb">enumerate</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">_classes</span><span class="p">):</span>  <span class="c1"># Calculate posterior for each class</span>
            <span class="n">prior</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">log</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">_priors</span><span class="p">[</span><span class="n">i</span><span class="p">])</span>
            <span class="n">posterior</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">sum</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">log</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">_pdf</span><span class="p">(</span><span class="n">i</span><span class="p">,</span> <span class="n">x</span><span class="p">)))</span>  <span class="c1"># Gaussian model</span>
            <span class="n">posterior</span> <span class="o">+=</span> <span class="n">prior</span>
            <span class="n">posteriors</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">posterior</span><span class="p">)</span>
        <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">_classes</span><span class="p">[</span><span class="n">np</span><span class="o">.</span><span class="n">argmax</span><span class="p">(</span><span class="n">posteriors</span><span class="p">)]</span>

    <span class="k">def</span> <span class="nf">_pdf</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">i</span><span class="p">,</span> <span class="n">x</span><span class="p">):</span>
        <span class="n">mean</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_mean</span><span class="p">[</span><span class="n">i</span><span class="p">]</span>
        <span class="n">var</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_var</span><span class="p">[</span><span class="n">i</span><span class="p">]</span>

        <span class="n">numerator</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">exp</span><span class="p">(</span><span class="o">-</span><span class="p">(((</span><span class="n">x</span> <span class="o">-</span> <span class="n">mean</span><span class="p">)</span> <span class="o">**</span> <span class="mi">2</span><span class="p">)</span> <span class="o">/</span> <span class="p">(</span><span class="mi">2</span> <span class="o">*</span> <span class="n">var</span><span class="p">)))</span>
        <span class="n">doneminator</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">sqrt</span><span class="p">(</span><span class="mi">2</span> <span class="o">*</span> <span class="n">np</span><span class="o">.</span><span class="n">pi</span> <span class="o">*</span> <span class="n">var</span><span class="p">)</span>
        <span class="k">return</span> <span class="n">numerator</span> <span class="o">/</span> <span class="n">doneminator</span>
</pre>
                            </div>
                          </div>
                        </div>
                      </div>
                      <div class="cell docutils container">
                        <div class="cell_input docutils container">
                          <div class="highlight-ipython3 notranslate">
                            <div class="highlight">
                              <pre><span></span><span class="c1"># Let&#39;s create a function to calculate the accuracy of our NB Classifier</span>
<span class="k">def</span> <span class="nf">accuracy</span><span class="p">(</span><span class="n">a</span><span class="p">,</span> <span class="n">b</span><span class="p">):</span>
    <span class="k">return</span> <span class="n">np</span><span class="o">.</span><span class="n">sum</span><span class="p">(</span><span class="n">a</span> <span class="o">==</span> <span class="n">b</span><span class="p">)</span> <span class="o">/</span> <span class="nb">len</span><span class="p">(</span><span class="n">a</span><span class="p">)</span>


<span class="c1"># Now, let&#39;s try our NB Classifier</span>
<span class="n">NB_scratch</span> <span class="o">=</span> <span class="n">NaiveBayes</span><span class="p">()</span>
<span class="n">NB_scratch</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">X_train</span><span class="p">,</span> <span class="n">y_train</span><span class="p">)</span>
<span class="n">y_pred</span> <span class="o">=</span> <span class="n">NB_scratch</span><span class="o">.</span><span class="n">predict</span><span class="p">(</span><span class="n">X_test</span><span class="p">)</span>

<span class="c1"># Let&#39;s check our model&#39;s accuracy</span>
<span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Naive Bayes accuracy: </span><span class="si">{</span><span class="n">accuracy</span><span class="p">(</span><span class="n">y_test</span><span class="p">,</span> <span class="n">y_pred</span><span class="p">)</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>
</pre>
                            </div>
                          </div>
                        </div>
                        <div class="cell_output docutils container">
                          <div
                            class="output stream highlight-myst-ansi notranslate"
                          >
                            <div class="highlight">
                              <pre><span></span>Naive Bayes accuracy: 0.7780872794800371
</pre>
                            </div>
                          </div>
                        </div>
                      </div>
                    </section>
                    <section id="built-in-naive-bayes-classifier">
                      <h3>
                        Built-in Naive Bayes Classifier<a
                          class="headerlink"
                          href="#built-in-naive-bayes-classifier"
                          title="Permalink to this heading"
                          >#</a
                        >
                      </h3>
                      <div class="cell docutils container">
                        <div class="cell_input docutils container">
                          <div class="highlight-ipython3 notranslate">
                            <div class="highlight">
                              <pre><span></span><span class="c1"># Let&#39;s train our model using Naive Bayes Classifier</span>
<span class="n">NB</span> <span class="o">=</span> <span class="n">GaussianNB</span><span class="p">()</span>
<span class="n">NB</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">X_train</span><span class="p">,</span> <span class="n">y_train</span><span class="p">)</span>
<span class="n">NB_pred</span> <span class="o">=</span> <span class="n">NB</span><span class="o">.</span><span class="n">predict</span><span class="p">(</span><span class="n">X_test</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Accuracy score for GaussianNB is </span><span class="si">{</span><span class="n">accuracy_score</span><span class="p">(</span><span class="n">y_test</span><span class="p">,</span> <span class="n">NB_pred</span><span class="p">)</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>

<span class="c1"># Let&#39;s plot the confusion matrix</span>
<span class="n">disp</span> <span class="o">=</span> <span class="n">ConfusionMatrixDisplay</span><span class="p">(</span><span class="n">confusion_matrix</span><span class="o">=</span><span class="n">confusion_matrix</span><span class="p">(</span>
    <span class="n">y_test</span><span class="p">,</span> <span class="n">NB_pred</span><span class="p">),</span> <span class="n">display_labels</span><span class="o">=</span><span class="p">[</span><span class="s1">&#39;Class 0&#39;</span><span class="p">,</span> <span class="s1">&#39;Class 1&#39;</span><span class="p">])</span>

<span class="n">disp</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="n">cmap</span><span class="o">=</span><span class="n">plt</span><span class="o">.</span><span class="n">cm</span><span class="o">.</span><span class="n">Blues</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">xlabel</span><span class="p">(</span><span class="s1">&#39;Predicted Label&#39;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">ylabel</span><span class="p">(</span><span class="s1">&#39;True Label&#39;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">title</span><span class="p">(</span><span class="s1">&#39;Confusion Matrix&#39;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">show</span><span class="p">()</span>

<span class="c1"># Let&#39;s plot the ROC Curve</span>
<span class="n">fpr</span><span class="p">,</span> <span class="n">tpr</span><span class="p">,</span> <span class="n">thresholds</span> <span class="o">=</span> <span class="n">roc_curve</span><span class="p">(</span><span class="n">y_test</span><span class="p">,</span> <span class="n">NB_pred</span><span class="p">)</span>
<span class="n">roc_display</span> <span class="o">=</span> <span class="n">RocCurveDisplay</span><span class="p">(</span><span class="n">fpr</span><span class="o">=</span><span class="n">fpr</span><span class="p">,</span> <span class="n">tpr</span><span class="o">=</span><span class="n">tpr</span><span class="p">,</span> <span class="n">roc_auc</span><span class="o">=</span><span class="n">roc_auc_score</span><span class="p">(</span>
    <span class="n">y_test</span><span class="p">,</span> <span class="n">NB_pred</span><span class="p">),</span> <span class="n">estimator_name</span><span class="o">=</span><span class="s1">&#39;Gausian Naive Bayes&#39;</span><span class="p">)</span>
<span class="n">roc_display</span><span class="o">.</span><span class="n">plot</span><span class="p">()</span>
<span class="n">plt</span><span class="o">.</span><span class="n">title</span><span class="p">(</span><span class="s1">&#39;Receiver Operating Characteristic (ROC) Curve&#39;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">show</span><span class="p">()</span>
</pre>
                            </div>
                          </div>
                        </div>
                        <div class="cell_output docutils container">
                          <div
                            class="output stream highlight-myst-ansi notranslate"
                          >
                            <div class="highlight">
                              <pre><span></span>Accuracy score for GaussianNB is 0.7780872794800371
</pre>
                            </div>
                          </div>
                          <img
                            alt="_images/20208f486521d9529d47e65534c0ead0a3d140d8344775f52ff7b22ab1c01881.png"
                            src="_images/20208f486521d9529d47e65534c0ead0a3d140d8344775f52ff7b22ab1c01881.png"
                          />
                          <img
                            alt="_images/60917560bdf6480791ec17777207c40cb0eee48862a8b4670a434d2989042bfa.png"
                            src="_images/60917560bdf6480791ec17777207c40cb0eee48862a8b4670a434d2989042bfa.png"
                          />
                        </div>
                      </div>
                    </section>
                  </section>
                  <section id="adaboost-classifier">
                    <h2>
                      Adaboost Classifier<a
                        class="headerlink"
                        href="#adaboost-classifier"
                        title="Permalink to this heading"
                        >#</a
                      >
                    </h2>
                    <p>
                      <strong>AdaBoost (Adaptive Boosting)</strong> is a machine
                      learning algorithm used for classification tasks. It
                      combines multiple “weak” classifiers, such as decision
                      stumps, into a single “strong” classifier. Initially, all
                      training examples are assigned equal weights. Weak
                      classifiers are trained sequentially, with weights
                      adjusted to focus on misclassified examples. The final
                      classifier is formed by combining the weak classifiers
                      based on their performance, with more accurate classifiers
                      having higher weights. To classify new instances, the weak
                      classifiers’ predictions are combined using their assigned
                      weights. AdaBoost leverages the concept of boosting to
                      iteratively improve its classification accuracy by
                      emphasizing challenging examples. This is how AdaBoost
                      works briefly:
                    </p>
                    <ol class="arabic simple">
                      <li>
                        <p>
                          Initialization: Each training example, denoted as
                          <span class="math notranslate nohighlight"
                            >\((x_i, y_i)\)</span
                          >
                          where
                          <span class="math notranslate nohighlight"
                            >\(x_i\)</span
                          >
                          is the input features and
                          <span class="math notranslate nohighlight"
                            >\(y_i\)</span
                          >
                          is the corresponding class label, is assigned an
                          initial weight,
                          <span class="math notranslate nohighlight"
                            >\(w_i = \frac{1}{n}\)</span
                          >, where n is the total number of training examples.
                        </p>
                      </li>
                      <li>
                        <p>
                          Training Weak Classifiers: AdaBoost sequentially
                          trains a series of weak classifiers. Each weak
                          classifier, denoted as
                          <span class="math notranslate nohighlight"
                            >\(h_t(x)\)</span
                          >, is trained on the weighted training data, where the
                          weights represent the importance of each example. The
                          weak classifier aims to minimize the weighted error
                          rate,
                          <span class="math notranslate nohighlight"
                            >\(Err_t\)</span
                          >, defined as the sum of weights of misclassified
                          examples:
                          <span class="math notranslate nohighlight"
                            >\(Err_t = Σ_i(w_i * I(y_i ≠ h_t(x_i)))\)</span
                          >
                        </p>
                      </li>
                      <li>
                        <p>
                          Weight Update: Once the weak classifier is trained,
                          its weight, α_t, is calculated based on its
                          performance:
                          <span class="math notranslate nohighlight"
                            >\(α_t = 0.5 * ln((1 - Err_t) / Err_t)\)</span
                          >. The weight
                          <span class="math notranslate nohighlight"
                            >\(α_t\)</span
                          >
                          measures the contribution of the weak classifier in
                          the final classification. Higher values of
                          <span class="math notranslate nohighlight"
                            >\(α_t\)</span
                          >
                          are assigned to more accurate classifiers, while lower
                          values are assigned to weaker ones. The weights of the
                          training examples are updated as follows:
                          <span class="math notranslate nohighlight"
                            >\(w_i ← w_i * exp(-α_t * y_i * h_t(x_i))\)</span
                          >. This update increases the weights of the
                          misclassified examples, making them more important for
                          subsequent classifiers to focus on.
                        </p>
                      </li>
                      <li>
                        <p>
                          Combining Classifiers: The final classification is
                          determined by combining the weak classifiers’
                          predictions using their weights. Given a new instance
                          x, the AdaBoost classifier output, H(x), is calculated
                          as:
                          <span class="math notranslate nohighlight"
                            >\(H(x) = sign(Σ_t(α_t * h_t(x)))\)</span
                          >. Here,
                          <span class="math notranslate nohighlight"
                            >\(sign()\)</span
                          >
                          returns the sign of the sum, indicating the predicted
                          class label (<span
                            class="math notranslate nohighlight"
                            >\(+1\)</span
                          >
                          or
                          <span class="math notranslate nohighlight"
                            >\(-1\)</span
                          >).
                        </p>
                      </li>
                    </ol>
                    <div class="cell docutils container">
                      <div class="cell_input docutils container">
                        <div class="highlight-ipython3 notranslate">
                          <div class="highlight">
                            <pre><span></span><span class="c1"># Let&#39;s build our classifier</span>
<span class="n">ada_classifier</span> <span class="o">=</span> <span class="n">AdaBoostClassifier</span><span class="p">()</span>
<span class="n">param_grid</span> <span class="o">=</span> <span class="p">{</span>
    <span class="s1">&#39;n_estimators&#39;</span><span class="p">:</span> <span class="p">[</span><span class="mi">30</span><span class="p">,</span> <span class="mi">31</span><span class="p">,</span> <span class="mi">32</span><span class="p">,</span> <span class="mi">33</span><span class="p">,</span> <span class="mi">34</span><span class="p">,</span> <span class="mi">35</span><span class="p">],</span>  <span class="c1"># Number of base estimators</span>
    <span class="s1">&#39;learning_rate&#39;</span><span class="p">:</span> <span class="p">[</span><span class="mf">0.4</span><span class="p">,</span> <span class="mf">0.5</span><span class="p">,</span> <span class="mf">0.6</span><span class="p">,</span> <span class="mf">0.7</span><span class="p">,</span> <span class="mf">0.8</span><span class="p">,</span> <span class="mf">0.9</span><span class="p">,</span> <span class="mf">1.0</span><span class="p">],</span>  <span class="c1"># Learning rate</span>
<span class="p">}</span>
<span class="n">random_search</span> <span class="o">=</span> <span class="n">RandomizedSearchCV</span><span class="p">(</span>
    <span class="n">ada_classifier</span><span class="p">,</span> <span class="n">param_distributions</span><span class="o">=</span><span class="n">param_grid</span><span class="p">,</span> <span class="n">n_iter</span><span class="o">=</span><span class="mi">10</span><span class="p">,</span> <span class="n">cv</span><span class="o">=</span><span class="mi">5</span><span class="p">)</span>
<span class="n">random_search</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">X_train</span><span class="p">,</span> <span class="n">y_train</span><span class="p">)</span>
<span class="n">best_params</span> <span class="o">=</span> <span class="n">random_search</span><span class="o">.</span><span class="n">best_params_</span>
<span class="n">best_score</span> <span class="o">=</span> <span class="n">random_search</span><span class="o">.</span><span class="n">best_score_</span>

<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;Best Hyperparameters:&quot;</span><span class="p">,</span> <span class="n">best_params</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;Best Score:&quot;</span><span class="p">,</span> <span class="n">best_score</span><span class="p">)</span>
</pre>
                          </div>
                        </div>
                      </div>
                      <div class="cell_output docutils container">
                        <div
                          class="output stream highlight-myst-ansi notranslate"
                        >
                          <div class="highlight">
                            <pre><span></span>Best Hyperparameters: {&#39;n_estimators&#39;: 34, &#39;learning_rate&#39;: 0.4}
Best Score: 0.8033417679221537
</pre>
                          </div>
                        </div>
                      </div>
                    </div>
                  </section>
                  <section id="random-forest-classifier-model">
                    <h2>
                      Random Forest Classifier Model<a
                        class="headerlink"
                        href="#random-forest-classifier-model"
                        title="Permalink to this heading"
                        >#</a
                      >
                    </h2>
                    <p>
                      <strong>The Random Forest classifier</strong> is a popular
                      machine learning algorithm used for classification tasks.
                      It belongs to the ensemble learning family and combines
                      the predictions of multiple decision trees to make
                      accurate predictions. Here’s a brief explanation of how
                      Random Forest works:
                    </p>
                    <ol class="arabic simple">
                      <li>
                        <p>
                          Random Subsampling: The algorithm starts by creating
                          an ensemble of decision trees. Each tree is trained on
                          a random subset of the training data, sampled with
                          replacement (known as bootstrap aggregating or
                          “bagging”). This creates diverse subsets of data for
                          each tree.
                        </p>
                      </li>
                      <li>
                        <p>
                          Feature Randomness: During the construction of each
                          decision tree, a random subset of features is
                          considered for splitting at each node. This introduces
                          further randomness and helps to reduce correlation
                          among the trees.
                        </p>
                      </li>
                      <li>
                        <p>
                          Decision Tree Construction: Each decision tree is
                          constructed by recursively partitioning the data based
                          on the selected features. The splitting is done based
                          on criteria such as Gini impurity or information gain,
                          aiming to create nodes that best separate the classes.
                        </p>
                      </li>
                      <li>
                        <p>
                          Voting for Classification: Once all the trees are
                          built, to classify a new instance, each tree
                          independently predicts the class label. The final
                          prediction is made by majority voting, where the class
                          that receives the most votes across all trees is
                          chosen as the final predicted class.
                        </p>
                      </li>
                    </ol>
                    <section id="rf-classifier">
                      <h3>
                        RF Classifier<a
                          class="headerlink"
                          href="#rf-classifier"
                          title="Permalink to this heading"
                          >#</a
                        >
                      </h3>
                      <div class="cell docutils container">
                        <div class="cell_input docutils container">
                          <div class="highlight-ipython3 notranslate">
                            <div class="highlight">
                              <pre><span></span><span class="c1"># Let&#39;s build our model</span>
<span class="n">rf_classifier</span> <span class="o">=</span> <span class="n">RandomForestClassifier</span><span class="p">(</span><span class="n">n_estimators</span><span class="o">=</span><span class="mi">300</span><span class="p">,</span> <span class="n">random_state</span><span class="o">=</span><span class="mi">42</span><span class="p">)</span>
<span class="n">rf_classifier</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">X_train</span><span class="p">,</span> <span class="n">y_train</span><span class="p">)</span>
<span class="n">rf_y_pred</span> <span class="o">=</span> <span class="n">rf_classifier</span><span class="o">.</span><span class="n">predict</span><span class="p">(</span><span class="n">X_test</span><span class="p">)</span>

<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;Accuracy:&quot;</span><span class="p">,</span> <span class="n">accuracy_score</span><span class="p">(</span><span class="n">y_test</span><span class="p">,</span> <span class="n">rf_y_pred</span><span class="p">))</span>
</pre>
                            </div>
                          </div>
                        </div>
                        <div class="cell_output docutils container">
                          <div
                            class="output stream highlight-myst-ansi notranslate"
                          >
                            <div class="highlight">
                              <pre><span></span>Accuracy: 0.8124419684308264
</pre>
                            </div>
                          </div>
                        </div>
                      </div>
                    </section>
                    <section id="features-impact-on-rf-model-s-prediction">
                      <h3>
                        Features Impact on RF Model’s Prediction<a
                          class="headerlink"
                          href="#features-impact-on-rf-model-s-prediction"
                          title="Permalink to this heading"
                          >#</a
                        >
                      </h3>
                      <div class="cell docutils container">
                        <div class="cell_input docutils container">
                          <div class="highlight-ipython3 notranslate">
                            <div class="highlight">
                              <pre><span></span><span class="c1"># We will use Shaply to explain how each feature impacts on the prediction of the RF model</span>

<span class="c1"># Create a SHAP TreeExplainer</span>
<span class="n">explainer</span> <span class="o">=</span> <span class="n">shap</span><span class="o">.</span><span class="n">TreeExplainer</span><span class="p">(</span><span class="n">rf_classifier</span><span class="p">)</span>
<span class="c1"># Generate SHAP values</span>
<span class="n">shap_values</span> <span class="o">=</span> <span class="n">explainer</span><span class="o">.</span><span class="n">shap_values</span><span class="p">(</span><span class="n">X_test</span><span class="p">)</span>
<span class="c1"># Plot the SHAP summary plot</span>
<span class="n">shap</span><span class="o">.</span><span class="n">summary_plot</span><span class="p">(</span><span class="n">shap_values</span><span class="p">,</span> <span class="n">X_test</span><span class="p">)</span>
</pre>
                            </div>
                          </div>
                        </div>
                        <div class="cell_output docutils container">
                          <img
                            alt="_images/d2c74d3367aa2ef6bea3d7d1c1f726ef3f03df5f8d2f913b34965154edf80f69.png"
                            src="_images/d2c74d3367aa2ef6bea3d7d1c1f726ef3f03df5f8d2f913b34965154edf80f69.png"
                          />
                        </div>
                      </div>
                    </section>
                    <section id="visualizing-the-tree-ensembles">
                      <h3>
                        Visualizing the Tree Ensembles<a
                          class="headerlink"
                          href="#visualizing-the-tree-ensembles"
                          title="Permalink to this heading"
                          >#</a
                        >
                      </h3>
                      <div class="cell docutils container">
                        <div class="cell_input docutils container">
                          <div class="highlight-ipython3 notranslate">
                            <div class="highlight">
                              <pre><span></span><span class="c1"># We will plot the tree ensembles of our RF model</span>

<span class="n">fig</span><span class="p">,</span> <span class="n">ax</span> <span class="o">=</span> <span class="n">plt</span><span class="o">.</span><span class="n">subplots</span><span class="p">(</span><span class="n">figsize</span><span class="o">=</span><span class="p">(</span><span class="mi">12</span><span class="p">,</span> <span class="mi">12</span><span class="p">))</span>
<span class="n">plot_tree</span><span class="p">(</span><span class="n">rf_classifier</span><span class="o">.</span><span class="n">estimators_</span><span class="p">[</span><span class="mi">0</span><span class="p">],</span> <span class="n">feature_names</span><span class="o">=</span><span class="nb">list</span><span class="p">(</span><span class="n">df</span><span class="o">.</span><span class="n">columns</span><span class="p">)[</span>
          <span class="p">:</span><span class="o">-</span><span class="mi">1</span><span class="p">],</span> <span class="n">class_names</span><span class="o">=</span><span class="nb">list</span><span class="p">(</span><span class="n">df</span><span class="o">.</span><span class="n">columns</span><span class="p">)[</span><span class="o">-</span><span class="mi">1</span><span class="p">],</span> <span class="n">filled</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span> <span class="n">ax</span><span class="o">=</span><span class="n">ax</span><span class="p">)</span>

<span class="n">output_file</span> <span class="o">=</span> <span class="s1">&#39;decision_tree.html&#39;</span>
<span class="n">mpld3</span><span class="o">.</span><span class="n">save_html</span><span class="p">(</span><span class="n">fig</span><span class="p">,</span> <span class="n">output_file</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Interactive decision tree saved as: </span><span class="si">{</span><span class="n">output_file</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>
</pre>
                            </div>
                          </div>
                        </div>
                        <div class="cell_output docutils container">
                          <div
                            class="output stream highlight-myst-ansi notranslate"
                          >
                            <div class="highlight">
                              <pre><span></span>Interactive decision tree saved as: decision_tree.html
</pre>
                            </div>
                          </div>
                          <img
                            alt="_images/9b141917441b1181c169fc5eb60492b8e0338510d7353b8317df52efff83cb59.png"
                            src="_images/9b141917441b1181c169fc5eb60492b8e0338510d7353b8317df52efff83cb59.png"
                          />
                        </div>
                      </div>
                    </section>
                  </section>
                  <section
                    id="using-an-ensemble-of-models-for-better-performance"
                  >
                    <h2>
                      Using an Ensemble of Models for Better Performance<a
                        class="headerlink"
                        href="#using-an-ensemble-of-models-for-better-performance"
                        title="Permalink to this heading"
                        >#</a
                      >
                    </h2>
                    <p>
                      Now, we will use several different classifiers (MLP
                      Classifier, Logistic Regression, SVC, RF Classifier), and
                      use a voting classifier to detect the best accuracy among
                      all these different classifiers.
                    </p>
                    <div class="cell docutils container">
                      <div class="cell_input docutils container">
                        <div class="highlight-ipython3 notranslate">
                          <div class="highlight">
                            <pre><span></span><span class="c1"># We will perform a standard scalar to our training and testing data</span>
<span class="n">scaler</span> <span class="o">=</span> <span class="n">StandardScaler</span><span class="p">()</span>
<span class="n">X_train_scaled</span> <span class="o">=</span> <span class="n">scaler</span><span class="o">.</span><span class="n">fit_transform</span><span class="p">(</span><span class="n">X_train</span><span class="p">)</span>
<span class="n">X_test_scaled</span> <span class="o">=</span> <span class="n">scaler</span><span class="o">.</span><span class="n">transform</span><span class="p">(</span><span class="n">X_test</span><span class="p">)</span>

<span class="c1"># Initialize individual classifiers</span>
<span class="n">classifier_1</span> <span class="o">=</span> <span class="n">RandomForestClassifier</span><span class="p">(</span><span class="n">random_state</span><span class="o">=</span><span class="mi">42</span><span class="p">)</span>
<span class="n">classifier_2</span> <span class="o">=</span> <span class="n">LogisticRegression</span><span class="p">(</span><span class="n">random_state</span><span class="o">=</span><span class="mi">42</span><span class="p">)</span>
<span class="n">classifier_3</span> <span class="o">=</span> <span class="n">SVC</span><span class="p">(</span><span class="n">random_state</span><span class="o">=</span><span class="mi">42</span><span class="p">,</span> <span class="n">probability</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
<span class="n">classifier_4</span> <span class="o">=</span> <span class="n">MLPClassifier</span><span class="p">(</span><span class="n">solver</span><span class="o">=</span><span class="s1">&#39;adam&#39;</span><span class="p">,</span> <span class="n">alpha</span><span class="o">=</span><span class="mf">1e-4</span><span class="p">,</span>
                             <span class="n">hidden_layer_sizes</span><span class="o">=</span><span class="p">(</span><span class="mi">5</span><span class="p">,</span> <span class="mi">2</span><span class="p">),</span> <span class="n">random_state</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span> <span class="n">max_iter</span><span class="o">=</span><span class="mi">500</span><span class="p">)</span>

<span class="c1"># Create the Voting Classifier</span>
<span class="n">voting_classifier</span> <span class="o">=</span> <span class="n">VotingClassifier</span><span class="p">(</span>
    <span class="n">estimators</span><span class="o">=</span><span class="p">[(</span><span class="s1">&#39;rf&#39;</span><span class="p">,</span> <span class="n">classifier_1</span><span class="p">),</span> <span class="p">(</span><span class="s1">&#39;lr&#39;</span><span class="p">,</span> <span class="n">classifier_2</span><span class="p">),</span>
                <span class="p">(</span><span class="s1">&#39;svm&#39;</span><span class="p">,</span> <span class="n">classifier_3</span><span class="p">),</span> <span class="p">(</span><span class="s2">&quot;MLP&quot;</span><span class="p">,</span> <span class="n">classifier_4</span><span class="p">)],</span>
    <span class="n">voting</span><span class="o">=</span><span class="s1">&#39;soft&#39;</span>
<span class="p">)</span>

<span class="c1"># Train the Voting Classifier</span>
<span class="n">voting_classifier</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">X_train_scaled</span><span class="p">,</span> <span class="n">y_train</span><span class="p">)</span>

<span class="n">y_pred</span> <span class="o">=</span> <span class="n">voting_classifier</span><span class="o">.</span><span class="n">predict</span><span class="p">(</span><span class="n">X_test_scaled</span><span class="p">)</span>

<span class="c1"># Evaluate the Voting Classifier</span>
<span class="n">accuracy</span> <span class="o">=</span> <span class="n">accuracy_score</span><span class="p">(</span><span class="n">y_test</span><span class="p">,</span> <span class="n">y_pred</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Accuracy: </span><span class="si">{</span><span class="n">accuracy</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>
</pre>
                          </div>
                        </div>
                      </div>
                      <div class="cell_output docutils container">
                        <div
                          class="output stream highlight-myst-ansi notranslate"
                        >
                          <div class="highlight">
                            <pre><span></span>Accuracy: 0.8115134633240483
</pre>
                          </div>
                        </div>
                      </div>
                    </div>
                  </section>
                </section>

                <script type="text/x-thebe-config">
                  {
                      requestKernel: true,
                      binderOptions: {
                          repo: "binder-examples/jupyter-stacks-datascience",
                          ref: "master",
                      },
                      codeMirrorConfig: {
                          theme: "abcdef",
                          mode: "python"
                      },
                      kernelOptions: {
                          name: "python3",
                          path: "./."
                      },
                      predefinedOutput: true
                  }
                </script>
                <script>
                  kernelName = 'python3';
                </script>
              </article>

              <footer class="bd-footer-article">
                <div class="footer-article-items footer-article__inner">
                  <div class="footer-article-item">
                    <!-- Previous / next buttons -->
                    <div class="prev-next-area">
                      <a
                        class="left-prev"
                        href="relations-visualization.html"
                        title="previous page"
                      >
                        <i class="fa-solid fa-angle-left"></i>
                        <div class="prev-next-info">
                          <p class="prev-next-subtitle">previous</p>
                          <p class="prev-next-title">
                            Visualizing Relations Between Features
                          </p>
                        </div>
                      </a>
                    </div>
                  </div>
                </div>
              </footer>
            </div>

            <div class="bd-sidebar-secondary bd-toc">
              <div class="sidebar-secondary-items sidebar-secondary__inner">
                <div class="sidebar-secondary-item">
                  <div class="page-toc tocsection onthispage">
                    <i class="fa-solid fa-list"></i> Contents
                  </div>
                  <nav class="bd-toc-nav page-toc">
                    <ul class="visible nav section-nav flex-column">
                      <li class="toc-h2 nav-item toc-entry">
                        <a
                          class="reference internal nav-link"
                          href="#naive-bayes-classifier"
                          >Naive Bayes Classifier</a
                        >
                        <ul class="nav section-nav flex-column">
                          <li class="toc-h3 nav-item toc-entry">
                            <a
                              class="reference internal nav-link"
                              href="#naive-bayes-classifier-from-scratch"
                              >Naive Bayes Classifier from Scratch</a
                            >
                          </li>
                          <li class="toc-h3 nav-item toc-entry">
                            <a
                              class="reference internal nav-link"
                              href="#built-in-naive-bayes-classifier"
                              >Built-in Naive Bayes Classifier</a
                            >
                          </li>
                        </ul>
                      </li>
                      <li class="toc-h2 nav-item toc-entry">
                        <a
                          class="reference internal nav-link"
                          href="#adaboost-classifier"
                          >Adaboost Classifier</a
                        >
                      </li>
                      <li class="toc-h2 nav-item toc-entry">
                        <a
                          class="reference internal nav-link"
                          href="#random-forest-classifier-model"
                          >Random Forest Classifier Model</a
                        >
                        <ul class="nav section-nav flex-column">
                          <li class="toc-h3 nav-item toc-entry">
                            <a
                              class="reference internal nav-link"
                              href="#rf-classifier"
                              >RF Classifier</a
                            >
                          </li>
                          <li class="toc-h3 nav-item toc-entry">
                            <a
                              class="reference internal nav-link"
                              href="#features-impact-on-rf-model-s-prediction"
                              >Features Impact on RF Model’s Prediction</a
                            >
                          </li>
                          <li class="toc-h3 nav-item toc-entry">
                            <a
                              class="reference internal nav-link"
                              href="#visualizing-the-tree-ensembles"
                              >Visualizing the Tree Ensembles</a
                            >
                          </li>
                        </ul>
                      </li>
                      <li class="toc-h2 nav-item toc-entry">
                        <a
                          class="reference internal nav-link"
                          href="#using-an-ensemble-of-models-for-better-performance"
                          >Using an Ensemble of Models for Better Performance</a
                        >
                      </li>
                    </ul>
                  </nav>
                </div>
              </div>
            </div>
          </div>
          <footer class="bd-footer-content">
            <div class="bd-footer-content__inner container">
              <div class="footer-item">
                <p class="component-author">By StatsXChange Team</p>
              </div>

              <div class="footer-item">
                <p class="copyright">
                  © Copyright 2023.
                  <br />
                </p>
              </div>

              <div class="footer-item"></div>

              <div class="footer-item"></div>
            </div>
          </footer>
        </main>
      </div>
    </div>

    <!-- Scripts loaded after <body> so the DOM is not blocked -->
    <script src="_static/scripts/bootstrap.js?digest=e353d410970836974a52"></script>
    <script src="_static/scripts/pydata-sphinx-theme.js?digest=e353d410970836974a52"></script>

    <footer class="bd-footer"></footer>
  </body>
</html>
